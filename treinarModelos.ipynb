{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a8cd5c9-fee6-4564-8736-438c67979782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25 23:34:50.878132: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "import h5py\n",
    "import csv\n",
    "import time\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Activation, Input, Concatenate, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks, optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1128523a-a737-4d05-8a04-4d461db04a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file_pointer(fp, tam):\n",
    "    lines = [ll.strip() for ll in fp]\n",
    "    ii = 0\n",
    "    labels = []\n",
    "    res = []\n",
    "    cli = []\n",
    "    numLinhas = 0\n",
    "    while ii < len(lines):\n",
    "        line = lines[ii]\n",
    "        #contando o numero de vertices do grafo\n",
    "        if \"cliqueatual\" not in line:\n",
    "            ii += 1\n",
    "            numLinhas += 1\n",
    "            continue\n",
    "\n",
    "        #pegando a clique atual\n",
    "        line = line[3:]\n",
    "        spritado = line.split()\n",
    "        clique = [int(elem) for elem in spritado[1:]]\n",
    "        if(numLinhas < tam):\n",
    "            dif = tam - numLinhas\n",
    "            clique.extend([0]*dif)\n",
    "        cli.append(clique)\n",
    "\n",
    "        #criando o vetor de movimento\n",
    "        line = lines[ii+1]\n",
    "        sp = line.split()\n",
    "        mv = int(sp[-1])\n",
    "        label = [0] * tam\n",
    "        label[mv] = 1\n",
    "        labels.append(label)\n",
    "\n",
    "        #lendo o grafo\n",
    "        cells = []\n",
    "        for tt in range(numLinhas, 0, -1):\n",
    "            cell_line = lines[ii - tt][3:]\n",
    "            cells.extend([int(float(cc)) for cc in cell_line.split(\", \")])\n",
    "            if(numLinhas < tam):\n",
    "                dif = tam - numLinhas\n",
    "                cells.extend([0]*dif)\n",
    "\n",
    "        #cells = np.reshape(cells,((tam,  -1)))\n",
    "        #cells = np.transpose(cells)\n",
    "        #cells = np.reshape(cells, -1)\n",
    "        res.append(cells)\n",
    "        ii += (numLinhas+2)\n",
    "    labels_v = list(range(len(labels),0, -1))\n",
    "    return (res, cli, labels, labels_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec6a7c5-ea3e-47a2-a1d3-d168e03916d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dir(ddir, tam):\n",
    "    res = []\n",
    "    cli = []\n",
    "    labels = []\n",
    "    labels_v = []\n",
    "    random.seed(42)\n",
    "    files = sorted([os.path.basename(ii) for ii in glob.glob(\"{0}/*.txt\".format(ddir))])\n",
    "    random.shuffle(files)\n",
    "    random.seed()\n",
    "    i = 0\n",
    "    for ff in files:\n",
    "        with open(os.path.join(ddir,ff), 'r') as fp:\n",
    "            rr,cc,ll,ll_v = parse_file_pointer(fp, tam)\n",
    "            print(\"\\nfim instancia\\n\")\n",
    "            res.extend(rr)\n",
    "            cli.extend(cc)\n",
    "            labels.extend(ll)\n",
    "            labels_v.extend(ll_v)\n",
    "        i+=1\n",
    "        if i > 5:\n",
    "            break\n",
    "    return res, cli, labels, labels_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae619989-ab64-4168-9a12-bc575a916901",
   "metadata": {},
   "outputs": [],
   "source": [
    "class printbatch(callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        logging.info(\"Epoch: \"+ str(epoch))\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logging.info(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e2016e-cf70-4e08-9a80-9d0159c2ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggerWriter:\n",
    "    def __init__(self, level):\n",
    "        self.level = level\n",
    "\n",
    "    def write(self, message):\n",
    "        if message != '\\n':\n",
    "            self.level(message)\n",
    "\n",
    "    def flush(self):\n",
    "        self.level(sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2809c21c-f5cb-4135-9ae5-e19e265a00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(data, clique, labels, tam, output_path, shared_layer_multipliers, layer_multipliers, batch_size, learning_rate):\n",
    "    \n",
    "    shared_layer_multipliers = [x for x in shared_layer_multipliers if x != 0]\n",
    "\n",
    "    # Definir camadas de entrada\n",
    "    graph_input = Input(shape=(tam, tam))  # Matriz de adjacência\n",
    "    clique_input = Input(shape=(tam,))  # Vetor de clique\n",
    "\n",
    "    # Camadas densas compartilhadas\n",
    "    graph_input_processed = graph_input\n",
    "    clique_input_processed = clique_input\n",
    "    for i in range(len(shared_layer_multipliers)):\n",
    "        shared_dense_graph = Dense(tam * shared_layer_multipliers[i], activation='relu')\n",
    "        shared_dense_clique = Dense(tam * shared_layer_multipliers[i], activation='relu')\n",
    "        graph_input_processed = shared_dense_graph(graph_input_processed)\n",
    "        clique_input_processed = shared_dense_clique(clique_input_processed)\n",
    "    \n",
    "    # Achatar a saída da matriz de adjacência\n",
    "    graph_input_processed = Flatten()(graph_input_processed)\n",
    "    \n",
    "    # Concatenar os vetores processados\n",
    "    merged_vector = Concatenate(axis=-1)([graph_input_processed, clique_input_processed])\n",
    "    \n",
    "    #camadas internas\n",
    "    layer = merged_vector\n",
    "    for i in range(len(layer_multipliers)):\n",
    "        layer = Dense(tam*layer_multipliers[i],activation='relu')(layer)\n",
    "        \n",
    "    #camada de saida\n",
    "    output_layer = Dense(tam, activation='softmax')(layer)\n",
    "    \n",
    "    #compilar modelo\n",
    "    model = Model(inputs=[graph_input, clique_input], outputs=output_layer)\n",
    "    adam = optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    #treinar modelo\n",
    "    now = datetime.now()\n",
    "    model.fit([data, clique], labels,nb_epoch= 1000,batch_size=batch_size,validation_split=0.2,verbose=2,\n",
    "              callbacks=[printbatch(), EarlyStopping(monitor='val_loss', patience=50, verbose=0), ModelCheckpoint(os.path.join(output_path, \"models\",\n",
    "                            \"dnn_model_\" + str(tam) + \"_\"+ str(now.day) + \".\" + str(now.month) + \".\" + str(now.year) + \"_\"\n",
    "                            + \"_{epoch:02d}-{val_loss:.2f}\" + \".h5\"),\n",
    "                            monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')])\n",
    "    model.save(os.path.join(output_path, \"dnn_model_\" + str(tam)+\"_\"+ str(now.day) + \".\" + str(now.month) + \".\" + str(now.year) +\"_\"+ \".h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b339dcc-d277-407b-8efc-e54f05d09306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_value(data, clique, labels, tam, output_path, shared_layer_multipliers, layer_multipliers, batch_size, learning_rate):\n",
    "   \n",
    "    shared_layer_multipliers = [x for x in shared_layer_multipliers if x != 0]\n",
    "\n",
    "    # Definir camadas de entrada\n",
    "    graph_input = Input(shape=(tam, tam))  # Matriz de adjacência\n",
    "    clique_input = Input(shape=(tam,))  # Vetor de clique\n",
    "\n",
    "    # Camadas densas compartilhadas\n",
    "    graph_input_processed = graph_input\n",
    "    clique_input_processed = clique_input\n",
    "    for i in range(len(shared_layer_multipliers)):\n",
    "        shared_dense_graph = Dense(tam * shared_layer_multipliers[i], activation='relu')\n",
    "        shared_dense_clique = Dense(tam * shared_layer_multipliers[i], activation='relu')\n",
    "        graph_input_processed = shared_dense_graph(graph_input_processed)\n",
    "        clique_input_processed = shared_dense_clique(clique_input_processed)\n",
    "    \n",
    "    # Achatar a saída da matriz de adjacência\n",
    "    graph_input_processed = Flatten()(graph_input_processed)\n",
    "    \n",
    "    # Concatenar os vetores processados\n",
    "    merged_vector = Concatenate(axis=-1)([graph_input_processed, clique_input_processed])\n",
    "    \n",
    "    #camadas internas\n",
    "    layer = merged_vector\n",
    "    for i in range(len(layer_multipliers)):\n",
    "        layer = Dense(tam*layer_multipliers[i],activation='relu')(layer)\n",
    "\n",
    "    #camada de saida\n",
    "    output_layer = Dense(1)(layer)\n",
    "\n",
    "    #compilar modelo\n",
    "    model = Model(inputs=[graph_input, clique_input], outputs=output_layer)\n",
    "    adam = optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=adam, loss='mse', metrics=['mae'])\n",
    "\n",
    "    #treinar modelo\n",
    "    now = datetime.datetime.now()\n",
    "    model.fit([data, clique], labels, nb_epoch=1000, batch_size=batch_size, validation_split=0.2, verbose=2,\n",
    "              callbacks=[printbatch(), EarlyStopping(monitor='val_loss', patience=50, verbose=0), ModelCheckpoint(os.path.join(output_path, \"models\",\n",
    "                            \"dnn_value_model_\" + str(tam) + \"x\" +\"_\"+ str(now.day) + \".\" + str(now.month) + \".\" + str(now.year) + \"_\" +\n",
    "                            \"_{epoch:02d}-{val_loss:.2f}\" + \".h5\"), monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False,\n",
    "                            mode='auto')])\n",
    "    model.save(os.path.join(output_path, \"dnn_value_model_\"+str(tam)+\"_\"+str(now.day)+\".\"+str(now.month)+\".\"+str(now.year)+\"_\"+\".h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6f3a334-c5de-4170-b29e-9ca2a5a25ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leu\n",
      "(0,)\n",
      "rede 1 treinada\n",
      "rede 2 treinada\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    output_path = \"modelos\" #caminha onde é salvo o modelo\n",
    "    labeled_data_dir = \"train_graphs\" #caminho dos dados para treinar o modelo\n",
    "    param_v_a_1 = [4, 3, 2] #camadas compartilhadas rede bound\n",
    "    param_v_a_2 = [3, 2, 2] #camadas ocultas\n",
    "    param_p_a_1 = [6, 4, 3] #camadas compartilhadas rede brach\n",
    "    param_p_a_2 = [9, 6, 2] #camadas ocultas\n",
    "    param_p_b = 512 #batch size\n",
    "    param_v_b =  512\n",
    "    param_p_l = 0.001 #taxa de aprendizado\n",
    "    param_v_l = 0.001 \n",
    "    tam = 250\n",
    "    use_value_model = True #se vai treinar a rede de bound\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    #treinar rede branch\n",
    "    res, clique, labels, labels_v = parse_dir(labeled_data_dir, tam)\n",
    "    print(\"leu\")\n",
    "    learn(np.array(res), np.array(clique), np.array(labels), tam, output_path, param_p_a_1, param_p_a_2, param_p_b, param_p_l)\n",
    "    print(\"rede 1 treinada\")\n",
    "    #treinar rede bound\n",
    "    if use_value_model:\n",
    "        learn_value(np.array(res), np.array(clique), np.array(labels_v), tam, output_path, param_v_a_1, param_v_a_2, param_v_b, param_v_l)\n",
    "        print(\"rede 2 treinada\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
